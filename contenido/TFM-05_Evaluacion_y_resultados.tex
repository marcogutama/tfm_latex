%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INICIO DEL CAPÍTULO 5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Evaluación y Resultados}
\label{chap:implementacion}
Este capítulo presenta la evaluación empírica y los resultados obtenidos al aplicar la metodología propuesta en esta tesis. Para validar la eficacia de la inteligencia artificial como herramienta de análisis de seguridad, la evaluación se desarrolla en dos fases principales.


Primero, se lleva a cabo una rigurosa comparativa entre cuatro modelos de IA de última generación y dos herramientas de referencia en la industria, SonarQube y Snyk. Utilizando un microservicio deliberadamente instrumentado con 13 vulnerabilidades comunes, se mide no solo la capacidad de detección de cada herramienta, sino también aspectos cualitativos como la calidad de las sugerencias de corrección y la profundidad del análisis. Además, se realiza un estudio cuantitativo del rendimiento y el coste computacional, factores cruciales para la viabilidad en un entorno de desarrollo real.


En la segunda parte, se exponen los resultados de la implementación práctica del modelo de IA más equilibrado en un pipeline de Integración y Despliegue Continuo (CI/CD) completamente automatizado. Se demuestra el ciclo completo de detección, bloqueo de código inseguro mediante un \textit{Quality Gate}, facilitación de la remediación a través de reportes accionables y, finalmente, la validación de las correcciones con una ejecución exitosa del pipeline.

\section{Evaluación}
\label{sec:evaluacion}
Para evaluar la eficacia de la integración de la inteligencia artificial en la detección de vulnerabilidades y mejora de la calidad del código, se ha utilizado un microservicio de ejemplo en Java (alojado en el repositorio \url{https://github.com/iJonnathan/TFM/tree/main/demo}), diseñado a propósito con múltiples fallos de seguridad. Este código fue analizado tanto por los modelos de IA como por dos herramientas de referencia que representan el estándar industrial: SonarQube y Snyk.

\subsection{Entorno de Pruebas y Análisis de Vulnerabilidades}

El componente central para la evaluación es el controlador \texttt{WelcomeController.java} y el fichero \texttt{pom.xml} del proyecto, que contienen un conjunto de vulnerabilidades clásicas para medir la capacidad de detección de las herramientas.

\subsubsection{Análisis Detallado de Vulnerabilidades Introducidas}

Para realizar una evaluación controlada, el microservicio de prueba fue deliberadamente instrumentado con un conjunto de vulnerabilidades, representativas de las categorías más comunes del OWASP Top 10. A continuación, se detalla cada una de ellas:

\textbf{1. Clave Secreta Embebida en el Código (CWE-798):} Se han incluido credenciales directamente en el código fuente.
\begin{lstlisting}[language=java, caption={Claves secretas hardcodeadas.}]
// Hardcoded secret (clave embebida)
private static final String DB_PASSWORD = "SuperSecreta123!";
private static final String API_KEY = "ABC123-TOKEN-INSEGURO";
\end{lstlisting}

\textbf{2. Cross-Site Scripting (XSS) Reflejado (CWE-79):} El endpoint \texttt{/api/welcome} concatena un parámetro en la respuesta sin saneamiento.
\begin{lstlisting}[language=java, caption={Código vulnerable a XSS.}]
@GetMapping("/api/welcome")
public WelcomeDTO welcome( @RequestParam(value = "name", defaultValue = "...") String name) {
    return new WelcomeDTO("Hola, bienvenido " + name + ", esto es un demo");
}
\end{lstlisting}

\textbf{3. Ejecución Remota de Código (RCE) (CWE-94):} El endpoint \texttt{/api/execute} evalúa una cadena del usuario como código, permitiendo la ejecución de comandos arbitrarios.
\begin{lstlisting}[language=java, caption={Código vulnerable a RCE.}]
@PostMapping("/api/execute")
public String executeCode( @RequestBody String userScript) throws Exception {
    ScriptEngine engine = new ScriptEngineManager().getEngineByName("nashorn");
    return "Resultado: " + engine.eval(userScript);
}
\end{lstlisting}

\textbf{4. Path Traversal (CWE-22):} El endpoint \texttt{/api/read-file} permite leer archivos del sistema sin una validación de ruta adecuada.
\begin{lstlisting}[language=java, caption={Código vulnerable a Path Traversal.}]
@GetMapping("/api/read-file")
public String readFile( @RequestParam String filePath) throws Exception {
    return Files.readString(Paths.get(filePath));
}
\end{lstlisting}

\textbf{5. Inyección SQL (CWE-89):} El endpoint \texttt{/api/user} construye una consulta SQL concatenando directamente la entrada del usuario.
\begin{lstlisting}[language=java, caption={Código vulnerable a Inyección SQL.}]
@GetMapping("/api/user")
public String getUserInfo( @RequestParam String username) throws Exception {
    Connection conn = DriverManager.getConnection("jdbc:mysql://localhost:3306/demo", "root", DB_PASSWORD);
    Statement stmt = conn.createStatement();
    ResultSet rs = stmt.executeQuery("SELECT * FROM users WHERE username = '" + username + "'");
    // ...
}
\end{lstlisting}

\textbf{6. Inyección de Comandos (CWE-78):} El endpoint \texttt{/api/ping} ejecuta un comando del sistema operativo concatenando la entrada del usuario.
\begin{lstlisting}[language=java, caption={Código vulnerable a Inyección de Comandos.}]
@PostMapping("/api/ping")
public String ping( @RequestBody String host) throws Exception {
    Process p = Runtime.getRuntime().exec("ping -c 1 " + host);
    // ...
}
\end{lstlisting}

\textbf{7. Deserialización Insegura (CWE-502):} El endpoint \texttt{/api/deserialize} deserializa un objeto de una fuente no confiable sin validación.
\begin{lstlisting}[language=java, caption={Código vulnerable a Deserialización Insegura.}]
@PostMapping("/api/deserialize")
public String deserialize( @RequestBody String base64) throws Exception {
    byte[] data = Base64.getDecoder().decode(base64);
    ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(data));
    Object obj = ois.readObject();
    return "Objeto: " + obj;
}
\end{lstlisting}

\textbf{8. Inserción de Información Sensible en Logs (CWE-532):} El endpoint \texttt{/api/login} registra credenciales en texto plano.
\begin{lstlisting}[language=java, caption={Logs con información sensible.}]
@PostMapping("/api/login")
public String login( @RequestParam String user, @RequestParam String password) {
    logger.info("Intento de login con usuario: " + user + " y contraseña: " + password); // Log inseguro
    return "Login procesado";
}
\end{lstlisting}

\textbf{9. Uso de Criptografía Débil (CWE-327):} El endpoint \texttt{/api/hash} utiliza el algoritmo MD5, que está criptográficamente roto.
\begin{lstlisting}[language=java, caption={Uso de un algoritmo de hash débil (MD5).}]
@GetMapping("/api/hash")
public String hash( @RequestParam String data) throws Exception {
    MessageDigest md = MessageDigest.getInstance("MD5"); // Inseguro
    byte[] digest = md.digest(data.getBytes());
    return Base64.getEncoder().encodeToString(digest);
}
\end{lstlisting}

\textbf{10. Cifrado Simétrico Débil (CWE-326):} El endpoint \texttt{/api/encrypt} usa AES con una clave estática y sin un modo de operación seguro (como GCM).
\begin{lstlisting}[language=java, caption={Cifrado simétrico débil (AES con clave fija).}]
@GetMapping("/api/encrypt")
public String encrypt( @RequestParam String text) throws Exception {
    String key = "1234567890123456"; // Clave estática
    SecretKeySpec secretKey = new SecretKeySpec(key.getBytes(), "AES");
    Cipher cipher = Cipher.getInstance("AES"); // sin GCM ni IV
    cipher.init(Cipher.ENCRYPT_MODE, secretKey);
    return Base64.getEncoder().encodeToString(cipher.doFinal(text.getBytes()));
}
\end{lstlisting}

\textbf{11. Exposición de Información Sensible por Error (CWE-209):} El endpoint \texttt{/api/error} devuelve detalles de la excepción al usuario.
\begin{lstlisting}[language=java, caption={Manejo de excepciones que expone información.}]
@GetMapping("/api/error")
public String error() {
    try {
        int a = 1 / 0;
        return "OK";
    } catch (Exception e) {
        return e.toString(); // Devuelve detalles internos
    }
}
\end{lstlisting}

\textbf{12. Dependencia Vulnerable (CWE-1104):} Se incluyó una versión antigua de la librería `jackson-databind` en el `pom.xml`, conocida por tener vulnerabilidades de deserialización.
\begin{lstlisting}[language=xml, caption={Dependencia vulnerable en pom.xml.}]
<dependency>
    <groupId>com.fasterxml.jackson.core</groupId>
    <artifactId>jackson-databind</artifactId>
    <version>2.9.8</version> 
</dependency>
\end{lstlisting}

\subsection{Modelos y Herramientas de Análisis}

Para llevar a cabo una evaluación exhaustiva y comparativa, se seleccionó un conjunto de modelos de IA de vanguardia y dos herramientas de referencia líderes en la industria.

Los modelos de IA, todos accesibles a través de la plataforma OpenRouter, fueron \footnote{Los modelos marcados como 'free' son ofrecidos por OpenRouter sin coste hasta un cierto límite de uso diario, lo que los hizo ideales para la experimentación en este trabajo de tesis.}:
\begin{itemize}
    \item \textbf{google/gemini-2.0-flash-exp:free}: Un modelo de última generación de Google, conocido por su velocidad y capacidades multimodales.
    \item \textbf{deepseek/deepseek-chat:free}: Un modelo de DeepSeek AI especializado y afinado para tareas de conversación y codificación.
    \item \textbf{deepseek/deepseek-r1-0528:free}: Un modelo de código abierto de DeepSeek de alto rendimiento.
    \item \textbf{qwen/qwen-2.5-coder-32b-instruct:free}: Un modelo de Qwen (Alibaba) especializado en código.
\end{itemize}

\paragraph{Herramientas de Referencia.}
\begin{itemize}
\item \textbf{SonarQube Community Edition 9.9}: Representa la línea base para el Análisis Estático de Seguridad de
Aplicaciones (SAST) y la calidad del código. Es una de las herramientas más utilizadas en la industria para el análisis del código fuente propio.
\item \textbf{Snyk (Plan Gratuito)}: Representa una solución de seguridad integral. Se utilizaron dos de sus capacidades principales, ambas disponibles en su plan gratuito: \begin{itemize}    \item \textbf{Snyk Open Source (SCA)}: Para el Análisis de Composición de Software, enfocado en detectar vulnerabilidades en dependencias de terceros a través del comando `snyk test`.    \item \textbf{Snyk Code (SAST)}: Para el Análisis Estático de Seguridad del código fuente propio, a través del comando `snyk code test`.\end{itemize}
\end{itemize}

\paragraph{Disponibilidad de los Reportes.} Para garantizar la transparencia y la reproducibilidad de esta evaluación, los reportes originales generados por SonarQube, Snyk y cada uno de los modelos de IA se han puesto a disposición pública en el repositorio del proyecto.


\subsection{Análisis Comparativo de Resultados}
\label{subsec:analisis_comparativo_resultados}
Cada modelo de IA y las herramientas de referencia analizaron el proyecto. La siguiente tabla detalla la detección de cada vulnerabilidad específica.

\newcommand{\cmark}{{\color{green!80!black}\checkmark}}%
\newcommand{\xmark}{{\color{red!80!black}\ding{55}}}%

\begin{table}[H]
\centering
\caption{Detección Detallada de Vulnerabilidades por Herramienta}
\label{tab:comparativa_detallada}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\textbf{Vulnerabilidad} & \textbf{SonarQube} & \textbf{Snyk (Free)} & \textbf{Gemini 2.0} & \textbf{DS Chat} & \textbf{DS R1} & 
\textbf{Qwen 2.5} \\
\hline
Hardcoded Secret (Password) & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\hline
Hardcoded Secret (API Key) & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\hline
Cross-Site Scripting (XSS) & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\hline
Remote Code Execution (RCE) & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\hline
Path Traversal & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\hline
Inyección SQL (SQLi) & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\hline
Inyección de Comandos & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\hline
Deserialización Insegura & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\hline
Logs con Datos Sensibles & \xmark & \xmark & \cmark & \cmark & \cmark & \cmark \\
\hline
Uso de Criptografía Débil (Hash) & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\hline
Cifrado Simétrico Débil & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\hline
Exposición de Error (Stacktrace) & \xmark & \xmark & \cmark & \cmark & \cmark & \cmark \\
\hline
Dependencia Vulnerable (pom.xml) & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\hline
\hline
\textbf{Total Código Fuente (12)} & 3 & 10 & 12 & 12 & 12 & 12 \\
\hline
\textbf{Total Dependencias (1)} & 0 & 1 & 1 & 1 & 1 & 1 \\
\hline
\end{tabular}%
}
\end{table}

\subsubsection{Análisis Cualitativo de las Respuestas de IA}

Como se estableció en la tabla \ref{tab:comparativa_detallada}, todos los modelos de IA demostraron una capacidad de detección del 100\% en el entorno de prueba. Este resultado, aunque impresionante, oculta diferencias cualitativas importantes. Para evaluar la calidad de las respuestas, las sugerencias de corrección se analizaron según tres criterios principales: \textbf{Seguridad de la Solución} (¿la corrección es robusta y no introduce nuevos fallos?), \textbf{Claridad de la Explicación} (¿es fácil de entender para un desarrollador?) y \textbf{Accionabilidad} (¿el código sugerido es directamente aplicable?). A continuación, se analizan ejemplos concretos que ilustran estas diferencias.

\paragraph{Profundidad y Seguridad de la Sugerencia de Corrección.}
Un buen indicador de la calidad de un modelo es la robustez de la solución que propone. Se puede observar una diferencia clara en la gestión de la vulnerabilidad de \textbf{Path Traversal (CWE-22)}.


\begin{itemize}
    \item El modelo \textbf{qwen/qwen-2.5-coder-32b-instruct:free} ofreció la siguiente sugerencia:
    \begin{lstlisting}[language=java,caption={Sugerencia de Qwen para Path Traversal.}]
// Sugerencia de corrección:
if (!filePath.startsWith("/safe/directory/")) {
    throw new IllegalArgumentException("Ruta inválida");
}
    \end{lstlisting}
    \textbf{Análisis:} Esta solución es superficial e insegura. Un atacante podría evadirla fácilmente utilizando secuencias de escape como `filePath = ``/safe/directory/../../etc/passwd'' ', ya que la cadena efectivamente comienza con el prefijo permitido, pero luego navega fuera del directorio seguro.

    \item En contraste, los modelos \textbf{google/gemini-2.0-flash-exp:free} y \textbf{deepseek/deepseek-r1-0528:free} proporcionaron una solución mucho más robusta y segura:
    \begin{lstlisting}[language=java,caption={Sugerencia de Gemini/DeepSeek para Path Traversal.}]
// Sugerencia de corrección:
Path safePath = Paths.get("/safe/directory/").resolve(filePath).normalize();
if (!safePath.startsWith(Paths.get("/safe/directory/"))) {
    throw new IllegalArgumentException("Invalid file path");
}
return Files.readString(safePath);
    \end{lstlisting}
    \textbf{Análisis:} Esta implementación es significativamente superior. El método `.normalize()` resuelve las secuencias `..`, eliminando los intentos de evasión. La posterior validación con `.startsWith()` sobre la ruta ya normalizada asegura que el acceso a ficheros se mantenga estrictamente dentro del directorio previsto. Este es un ejemplo claro de cómo, a pesar de que ambos modelos detectaron la vulnerabilidad, solo uno proporcionó una corrección verdaderamente segura y accionable para el desarrollador.
\end{itemize}

\paragraph{Riqueza del Análisis: Más Allá de la Seguridad.}
Otro diferenciador clave es la capacidad de algunos modelos para ofrecer observaciones valiosas sobre la calidad y mantenibilidad del código, incluso en ficheros sin vulnerabilidades de seguridad. El análisis del fichero \texttt{WelcomeDTO.java} (un simple DTO) es un buen ejemplo.

\begin{itemize}
    \item El modelo \textbf{deepseek/deepseek-r1-0528:free} identificó una mejora de fiabilidad importante:
    \begin{quote}
        \textbf{Descripción:} Class does not override equals() and hashCode(). This may cause unexpected behavior when used in collections. \\
        \textbf{Recomendación:} Implement equals() and hashCode() based on the message field.
    \end{quote}
    \textbf{Análisis:} Esta es una sugerencia de alta calidad. No implementar `equals()` y `hashCode()` en DTOs es una causa frecuente de comportamientos anómalos y errores de difícil depuración cuando estos objetos se utilizan en colecciones como `HashMap` o `HashSet`. Este tipo de feedback proactivo ayuda a mejorar la robustez general de la aplicación.

    \item Por su parte, el modelo \textbf{google/gemini-2.0-flash-exp:free} se enfocó en un principio de diseño de software:
    \begin{quote}
        \textbf{Descripción:} The `message` field is mutable due to the presence of a setter method. For simple DTOs, immutability can improve thread safety and predictability. \\
        \textbf{Recomendación:} If the message should not be changed after creation, remove the `setMessage` method and make the `message` field final.
    \end{quote}
    \textbf{Análisis:} Esta también es una recomendación valiosa que apunta a mejorar la mantenibilidad y a prevenir efectos secundarios no deseados, promoviendo un diseño más funcional y seguro en entornos concurrentes.
\end{itemize}

Estos ejemplos demuestran que, si bien la cobertura de detección de vulnerabilidades es una métrica base, la verdadera diferenciación y el valor para un equipo de desarrollo radican en la calidad, profundidad y seguridad de las recomendaciones generadas, así como en la capacidad del modelo para actuar como un revisor de código integral.

\subsubsection{Análisis Cuantitativo de Rendimiento y Coste}

Más allá de la calidad de la detección, la viabilidad de integrar una solución de IA en un pipeline de CI/CD depende críticamente de dos factores cuantitativos: el \textbf{rendimiento} (tiempo de ejecución) y el \textbf{coste} (consumo de tokens). Un análisis lento puede crear cuellos de botella en el ciclo de desarrollo, mientras que un alto consumo de tokens puede hacer que la solución sea económicamente inviable a escala.

\paragraph{La Importancia de los Tokens.} En los modelos de IA comerciales, el coste se factura por el número de \textit{tokens} procesados. Un token es una unidad de texto (aproximadamente 4 caracteres en inglés). El coste total de una llamada a la API se compone de:
\begin{itemize}
    \item \textbf{Tokens de Entrada (Prompt Tokens):} El tamaño del código y las instrucciones enviadas al modelo. En este experimento, los tokens de entrada fueron constantes para todos los modelos, ya que analizaron los mismos ficheros.
    \item \textbf{Tokens de Salida (Completion Tokens):} El tamaño de la respuesta JSON generada por el modelo. Una respuesta más detallada, con descripciones más largas y sugerencias de código más elaboradas, consume más tokens de salida y, por lo tanto, es más costosa.
\end{itemize}

Para evaluar estos factores, se midió el tiempo de ejecución de cada análisis y se utilizó el tamaño en bytes del fichero de resultados JSON como una métrica proxy del consumo de tokens de salida.
\begin{table}[H]
    \centering
    \caption{Comparativa de Rendimiento y Consumo de Tokens}
    \label{tab:rendimiento_coste}
    \begin{tabular}{|l|c|c|l|}
        \hline
        \textbf{Modelo de IA}                   & \textbf{\makecell{Tiempo de \\ Análisis}} & \textbf{\makecell{Tamaño de \\ Respuesta \\ (Proxy de Tokens)}} & \textbf{Análisis} \\
        \hline
        gemini-2.0-flash-exp:free           & 1 min 38 seg                              & 45.6 KB                                                         & Rápido y detallado \\
        \hline
        deepseek-chat:free                  & 8 min 13 seg                              & 24.8 KB                                                         & \makecell[l]{Lento y moderadamente \\ detallado} \\
        \hline
        deepseek-r1-0528:free               & 18 min 49 seg                             & 16.1 KB                                                         & Muy lento y conciso \\
        \hline
        qwen-2.5-coder-32b-instruct:free    & 4 min 54 seg                              & 49.2 KB                                                & \makecell[l]{Velocidad media, \\ respuesta más extensa} \\
        \hline
    \end{tabular}
\end{table}

\paragraph{Discusión de los Resultados.}
La Tabla \ref{tab:rendimiento_coste} revela un interesante equilibrio entre velocidad, coste y verbosidad:
\begin{itemize}
    \item El modelo \textbf{qwen/qwen-2.5-coder-32b-instruct:free} generó la respuesta más detallada (mayor tamaño), lo que implica un mayor coste en tokens, pero lo hizo en un tiempo razonable. Esto sugiere que es un modelo que prioriza la exhaustividad en sus explicaciones.
    \item El modelo \textbf{google/gemini-2.0-flash-exp:free} emerge como el más equilibrado para un entorno de CI/CD. Ofrece una velocidad de ejecución excepcional (casi 5 veces más rápido que el siguiente) y genera una respuesta muy detallada, representando una excelente relación entre eficiencia, coste y calidad de la información.
    \item El modelo \textbf{deepseek/deepseek-r1-0528:free}, a pesar de ser el más lento, fue sorprendentemente el más conciso en su respuesta. Esto indica un estilo de comunicación muy directo, que podría ser preferible en algunos contextos, pero su alto tiempo de ejecución lo hace menos ideal para pipelines de integración continua que requieren retroalimentación rápida.
\end{itemize}

Este análisis cuantitativo es fundamental para la toma de decisiones en un entorno real. Un equipo podría optar por usar un modelo rápido y económico como \texttt{google/gemini-2.0-flash-exp:free} para las revisiones en cada commit, y reservar el uso de un modelo más lento pero potencialmente más exhaustivo en sus explicaciones para los escaneos nocturnos o previos al despliegue.


\subsection{Discusión General y Conclusiones de la Evaluación}

Del análisis detallado de los resultados, se extraen las siguientes observaciones clave:

\begin{itemize}
    \item \textbf{Rendimiento de las Herramientas de Referencia (Baselines)}: Las herramientas especializadas demostraron ser eficaces en sus respectivos dominios, pero con diferentes niveles de cobertura.
        \begin{itemize}
            \item \textbf{SonarQube (SAST)}: Detectó 3 de las 12 vulnerabilidades del código fuente, enfocándose en patrones de calidad y seguridad evidentes (como las claves embebidas), pero no identificó vulnerabilidades contextuales complejas (SQLi, XSS) ni la dependencia vulnerable. Su valor principal reside en la gobernanza de la calidad del código.
            \item \textbf{Snyk (SAST y SCA)}: Demostró una alta eficacia en ambos frentes. Su motor SAST (`Snyk Code`) detectó 10 de las 12 vulnerabilidades del código fuente, fallando únicamente en la detección de logs con datos sensibles y la exposición de errores. Su motor SCA (`Snyk Open Source`) identificó correctamente la dependencia vulnerable en el `pom.xml`. Esto la posiciona como una herramienta de seguridad muy robusta.
        \end{itemize}

    \item \textbf{Rendimiento Holístico de los Modelos de IA}: El hallazgo más significativo es la capacidad de los modelos de IA para realizar un análisis híbrido, cubriendo tanto las responsabilidades de SAST como de SCA con una eficacia del 100\% en el entorno de prueba. Todos los modelos identificaron la totalidad de las 13 vulnerabilidades, superando incluso la cobertura de Snyk y demostrando una comprensión contextual superior.

    \item \textbf{Nuevos Criterios de Diferenciación: Detección vs. Asistencia}: Dado que tanto la IA como Snyk muestran una alta capacidad de detección, el criterio de diferenciación se desplaza. La pregunta ya no es solo \textit{¿qué herramienta encuentra más fallos?}, sino \textit{¿qué herramienta ayuda mejor al desarrollador a corregirlos?} Aquí es donde la IA generativa aporta un valor único, al proporcionar explicaciones detalladas y sugerencias de código contextualizadas, un enfoque más pedagógico que el de las herramientas tradicionales.

    \item \textbf{Complementariedad Re-evaluada}: La estrategia de seguridad en un pipeline moderno debe ser vista como un sistema de capas.
        \begin{itemize}
            \item \textbf{Capa 1 (Calidad):} SonarQube sigue siendo fundamental para aplicar un conjunto de reglas de código de forma rápida y consistente, manteniendo la salud general del código.
            \item \textbf{Capa 2 (Detección):} Herramientas como Snyk ofrecen una detección de seguridad SAST y SCA muy competente y fiable, actuando como una red de seguridad robusta.
            \item \textbf{Capa 3 (Asistencia y Aceleración):} La IA generativa, como la implementada en esta tesis, se posiciona como una capa superior. No solo detecta, sino que acelera la remediación, reduce la carga cognitiva del desarrollador y sirve como una herramienta de aprendizaje continuo, mejorando las capacidades de seguridad del equipo.
        \end{itemize}
\end{itemize}

La evaluación empírica llevada a cabo en este trabajo permite extraer una conclusión fundamental: la integración de la Inteligencia Artificial en los pipelines de CI/CD para el análisis de seguridad no solo es viable, sino que representa la siguiente evolución en las prácticas de DevSecOps, yendo más allá de la simple detección para enfocarse en la asistencia inteligente.

Mientras que herramientas como SonarQube son indispensables para la gobernanza de la calidad y Snyk ofrece una detección de vulnerabilidades SAST y SCA muy sólida, los modelos de IA evaluados han demostrado un potencial superior en dos áreas clave:
\begin{enumerate}
    \item \textbf{Cobertura de Detección Holística:} Los modelos de IA fueron los únicos capaces de identificar el 100\% de las vulnerabilidades de código y de dependencias en el entorno de prueba, demostrando una capacidad de análisis contextual que supera a las herramientas de referencia.
    \item \textbf{Asistencia para la Remediación:} El valor más significativo de la IA no reside en su capacidad de detección, sino en la calidad de la asistencia que proporciona. Al generar explicaciones claras y fragmentos de código directamente aplicables, la IA reduce drásticamente el tiempo y el esfuerzo que los desarrolladores deben invertir en investigar y corregir vulnerabilidades, convirtiendo un reporte de seguridad en un plan de acción concreto.
\end{enumerate}

En definitiva, una estrategia de DevSecOps madura debería considerar un enfoque híbrido y por capas. Utilizar SonarQube para la calidad, apoyarse en herramientas robustas como Snyk para una detección fiable, y complementar el ecosistema con un sistema de asistencia basado en IA para acelerar la corrección y mejorar las habilidades del equipo de desarrollo. Este trabajo demuestra que el futuro de la seguridad en el desarrollo de software no está solo en encontrar más fallos, sino en solucionarlos de manera más rápida, eficiente e inteligente.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FIN DEL CAPÍTULO 4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Resultados de la Ejecución del Pipeline}
\label{subsec:analisis_resultados_pipeline}

Para la validación empírica de la solución, se diseñó una prueba específica utilizando el microservicio (`demo`). A diferencia de la comparativa inicial que abarcó trece vulnerabilidades, esta fase se concentró en un subconjunto de \textbf{cinco vulnerabilidades} para evaluar de forma precisa el comportamiento de la solución integrada en el pipeline.

El modelo de IA seleccionado para esta prueba fue \texttt{gemini-2.0-flash-exp}. Esta elección se justifica por su rendimiento superior en la evaluación comparativa (sección \ref{subsec:analisis_comparativo_resultados}), donde demostró el mejor equilibrio entre precisión, calidad de las sugerencias y eficiencia.

Con el entorno CI/CD completamente automatizado, la ejecución del pipeline se activó tras realizar un `commit` en el repositorio, cumpliendo con el requisito \textbf{RF-01}. La vista general del proceso, con las etapas completadas y el punto de fallo, se puede apreciar en la Figura \ref{fig:pipeline_general_fail}.

\begin{figure}[h]
\centering
\includegraphics[width=0.99\textwidth]{contenido/imagenes/4_pipeline_fail.png}
\caption{Ejecución fallida del pipeline.}
\label{fig:pipeline_general_fail}
\end{figure}

\subsubsection{Flujo de Ejecución y Falla Controlada en el Quality Gate}
El pipeline ejecutó las primeras etapas de manera secuencial y paralela, tal como fue diseñado, recopilando información de seguridad en cada paso antes de llegar al punto de control crítico.

\begin{enumerate}
    \item Las etapas iniciales, \textbf{Checkout \& Build} y \textbf{Unit Test Reports}, se completaron con éxito. El código fue clonado, la aplicación fue empaquetada con Maven (\textbf{RF-02}), y los reportes de pruebas unitarias fueron procesados por Jenkins, sin embargo, una de las pruebas unitarias saltó una excepción debido a una vulnerabilidad de dependencia en el pom.xml, el cual fue detectada en el stage AI-Powered Analysis.
    \item La etapa \textbf{Static Analysis} se ejecutó, realizando sus tareas en paralelo para optimizar el tiempo.
    \item La etapa \textbf{AI-Powered Analysis} se completó satisfactoriamente, cumpliendo su objetivo principal (\textbf{RF-04}). El script de Python interactuó con la API de la IA y generó los artefactos cruciais: el reporte HTML para el desarrollador (`ai-analysis-report.html`) y el reporte JSON (`analysis-results.json`) para la automatización, cumpliendo así con \textbf{RF-05}.
    \item La ejecución llegó a la etapa \textbf{Quality Gate}. Este es el punto de control automatizado que implementa la política de seguridad del pipeline. El script leyó el archivo analysis-results.json y, tal como se esperaba, encontró que el valor de high\_severity\_vulnerabilities era de 5. 
\end{enumerate}

Debido a que este valor era mayor que el umbral de cero definido en la política, la condición del Quality Gate se activó y ejecutó el paso error(). Este comando detuvo inmediatamente el pipeline y lo marcó con el estado \textbf{FAILURE}, como se evidencia en la captura de la Figura \ref{fig:pipeline_general_fail}. Como resultado, las etapas posteriores Debug Path, Build Docker Image y Local Deploy nunca se ejecutaron.

Este fallo controlado es un éxito rotundo para el experimento. Demuestra que el sistema funciona como un mecanismo de seguridad preventivo eficaz (cumpliendo \textbf{RF-06}), deteniendo físicamente la promoción de código inseguro a través del ciclo de vida de desarrollo.

\subsubsection{Análisis Detallado del Reporte Generado por la IA}
La pieza clave generada por el pipeline es el reporte en formato HTML. Este documento, fácil de leer para los desarrolladores, es la principal herramienta para entender y solucionar los problemas encontrados. El reporte completo de esta ejecución se encuentra en el \textbf{Anexo \ref{anexo:ai-analysis-report}}.

A continuación, se explican los problemas más graves que encontró la IA y que causaron la falla del Quality Gate.

\paragraph{Dependencia Vulnerable en `pom.xml` (Severidad: HIGH)}
\begin{itemize}
    \item \textbf{Hallazgo:} La IA revisó el archivo pom.xml y vio que se usaba la versión 2.9.8 de la librería jackson-databind. Avisó que esta versión es muy antigua y tiene fallos de seguridad graves (CVEs) que podrían permitir a un atacante ejecutar código en el servidor.
    \item \textbf{Sugerencia de la IA:} La solución fue simple y directa: actualizar la librería a una versión más nueva y segura (como 2.16.1 o superior) en el archivo pom.xml.
\end{itemize}

\paragraph{Inyección SQL (Severidad: CRITICAL)}
\begin{itemize}
    \item \textbf{Hallazgo:} En el WelcomeController, la IA detectó que una consulta a la base de datos se estaba construyendo uniendo texto con datos que venían de un usuario, sin ninguna protección. Esto es un riesgo clásico de Inyección SQL.
    \item \textbf{Sugerencia de la IA:} Recomendó usar consultas preparadas (PreparedStatement), que es la forma correcta y segura de hacerlo, e incluyó un ejemplo de código de cómo implementarlo.
\end{itemize}

\paragraph{Ejecución Remota de Código (RCE) (Severidad: CRITICAL)}
\begin{itemize}
    \item \textbf{Hallazgo:} El sistema identificó que una parte del código ScriptEngine.eval() ejecutaba comandos directamente de la entrada del usuario, lo que es un riesgo crítico.
    \item \textbf{Sugerencia de la IA:} La recomendación fue eliminar esa función por completo, lo cual es la decisión más segura cuando una característica es tan peligrosa.
\end{itemize}

\paragraph{Path Traversal (Severidad: HIGH)}
\begin{itemize}
    \item \textbf{Hallazgo:} La IA señaló que una función que leía archivos tomaba la ruta del archivo directamente de la entrada del usuario, lo que le permitiría a un atacante leer archivos prohibidos del sistema usando secuencias como `../`.
    \item \textbf{Sugerencia de la IA:} Sugirió añadir código para verificar que la ruta del archivo solicitado estuviera siempre dentro de una carpeta base segura y permitida.
\end{itemize}

\paragraph{Claves Secretas en el Código (Severidad: CRITICAL)}
\begin{itemize}
    \item \textbf{Hallazgo:} El modelo encontró que la contraseña de la base de datos y una clave de API estaban escritas directamente en el código.
    \item \textbf{Sugerencia de la IA:} Recomendó seguir las mejores prácticas de seguridad (cumpliendo \textbf{RNF-03}) y mover estos secretos a variables de entorno o a un sistema de gestión de credenciales, en lugar de tenerlos en el código.
\end{itemize}
\subsubsection{Remediación y Ejecución Exitosa del Pipeline}
\label{subsec:remediacion_exitosa}

El valor fundamental del prototipo no reside únicamente en la detección, sino en su capacidad para facilitar una remediación rápida y precisa. Con las instrucciones claras y los ejemplos de código proporcionados por el reporte de la IA, un desarrollador pudo proceder a corregir las 5 vulnerabilidades críticas identificadas. El proceso de remediación consistió en:
\begin{itemize}
    \item Actualizar la versión de la dependencia `jackson-databind` en el archivo `pom.xml` a una versión segura.
    \item Refactorizar el método `getUserInfo` en WelcomeController.java para utilizar PreparedStatement, eliminando así la vulnerabilidad de Inyección SQL.
    \item Eliminar por completo los métodos inseguros executeCode (RCE) y ping (Command Injection).
    \item Añadir la lógica de validación de rutas en el método readFile para prevenir el Path Traversal.
    \item Externalizar las claves secretas (`DB\_PASSWORD` y `API\_KEY`), eliminándolas del código fuente y configurándolas como variables de entorno seguras.
\end{itemize}

Una vez aplicados estos cambios y subido el código corregido al repositorio de GitHub, el pipeline de Jenkins se ejecutó por segunda vez.

En esta nueva ejecución, el flujo de trabajo fue notablemente diferente. La etapa de `AI-Powered Analysis` analizó el código corregido y generó un nuevo reporte que no contenía ninguna vulnerabilidad de severidad `HIGH` o `CRITICAL`. Consecuentemente, al llegar a la etapa de `Quality Gate`, el resultado fue positivo. El log de la consola mostró el mensaje esperado: `QUALITY GATE PASSED: No se encontraron vulnerabilidades de severidad ALTA.`.

Al superar con éxito esta puerta de calidad, en primer lugar, la etapa de pruebas unitarias que anteriormente falló, esta vez ejecutó con éxito las 2 pruebas unitarias. El pipeline no se detuvo, continuó su ejecución a través de las etapas restantes:

\begin{enumerate}
    \item La etapa \textbf{Build Docker Image} se ejecutó sin problemas, tomando el archivo `.jar` seguro y empaquetándolo en una imagen Docker llamada `demo-app`.
    \item La etapa final, \textbf{Local Deploy}, también se completó exitosamente. Detuvo y eliminó cualquier versión anterior del contenedor de la aplicación y desplegó la nueva imagen, dejando el microservicio corregido y funcional, tal como se observa en la \textbf{Figura \ref{fig:deploy_exitoso}}.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{contenido/imagenes/4_deploy_ok.png}
    \caption{Despliegue exitoso de la etapa de despliegue.}
    \label{fig:deploy_exitoso}
\end{figure}

En conclusión, el ciclo de evaluación demostró ser un éxito completo. La primera ejecución validó la capacidad del sistema para detectar riesgos y actuar como un mecanismo de control preventivo, deteniendo un despliegue inseguro. La segunda ejecución, tras aplicar las correcciones sugeridas por la IA, validó la utilidad y precisión de dichas sugerencias, permitiendo que un artefacto seguro completara el pipeline de principio a fin, como se evidencia en la ejecución final de la \textbf{Figura \ref{fig:pipeline_exitoso}}. Este proceso empírico confirma que la integración de asistencia por IA en un pipeline CI/CD no solo es viable, sino que acelera eficazmente el ciclo de remediación, cumpliendo así con los objetivos centrales de esta tesis.

\begin{figure}[H] 
    \centering
    \includegraphics[width=0.9\textwidth]{contenido/imagenes/4_pipeline_ok.png}
    \caption{Ejecución exitosa del pipeline.}
    \label{fig:pipeline_exitoso}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FIN DEL CAPÍTULO 5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%